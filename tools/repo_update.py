import os
import textwrap
from typing import Optional

from ditk import logging
from hbutils.system import TemporaryDirectory
from hfutils.operate import upload_directory_as_directory
from hfutils.operate.base import RepoTypeTyping

from abstractor.openai import ask_llm
from abstractor.repository import get_hf_repo_abstract_prompt

_EXPECTED_TASKS = [
    'text-classification', 'token-classification', 'table-question-answering', 'question-answering',
    'zero-shot-classification', 'translation', 'summarization', 'feature-extraction', 'text-generation', 'fill-mask',
    'sentence-similarity', 'text-to-speech', 'text-to-audio', 'automatic-speech-recognition', 'audio-to-audio',
    'audio-classification', 'audio-text-to-text', 'voice-activity-detection', 'depth-estimation',
    'image-classification', 'object-detection', 'image-segmentation', 'text-to-image', 'image-to-text',
    'image-to-image', 'image-to-video', 'unconditional-image-generation', 'video-classification',
    'reinforcement-learning', 'robotics', 'tabular-classification', 'tabular-regression', 'tabular-to-text',
    'table-to-text', 'multiple-choice', 'text-ranking', 'text-retrieval', 'time-series-forecasting', 'text-to-video',
    'image-text-to-text', 'visual-question-answering', 'document-question-answering', 'zero-shot-image-classification',
    'graph-ml', 'mask-generation', 'zero-shot-object-detection', 'text-to-3d', 'image-to-3d',
    'image-feature-extraction', 'video-text-to-text', 'keypoint-detection', 'visual-document-retrieval', 'any-to-any',
    'video-to-video', 'other'
]


def sync(repo_id: str, repo_type: RepoTypeTyping = 'dataset', revision: str = 'main',
         hf_token: Optional[str] = None, max_retries: int = 5, max_sample_count: int = 15,
         extra_text: str = ''):
    _SYSTEM_PROMPT = textwrap.dedent(f"""
You are an expert AI assistant specialized in creating professional README.md files for Hugging Face repositories. Follow these comprehensive guidelines to generate perfect documentation:

#### 1. Repository Type Identification
- **Mandatory**: User will specify if it's a `model` or `dataset` repository
- If unspecified, infer from file structure:
  - Model indicators: `pytorch_model.bin`, `model.safetensors`, `config.json`
  - Dataset indicators: `dataset_info.json`, `data/*.arrow`, `data/*.parquet`

#### 2. Metadata Block Requirements
**Position**: Must be the first element in README, wrapped in `---`

**Model Repository Metadata**:
```yaml
pipeline_tag: (REQUIRED) # Official task type
  - Options: {", ".join(_EXPECTED_TASKS)}
  - Format: Single string value (must be one of the above)

license: (REQUIRED) # SPDX identifier
  - Options: apache-2.0, mit, bsd-3-clause, gpl-3.0, cc-by-4.0, 
             cc-by-sa-4.0, openrail, creativeml-openrail-m
  - Default: apache-2.0 (if no original license found)

tags: (STRONGLY RECOMMENDED)
  - Structure: Array of strings
  - Minimum: 3 tags (task type + framework + architecture)
  - Framework options: pytorch, tensorflow, jax, onnx, scikit-learn
  - Architecture options: bert, roberta, gpt2, t5, resnet, yolos

# Optional fields (include if information available)
datasets: 
  - Format: [glue, squad, username/custom-dataset]
metrics:
  - Format: [accuracy, f1, bleu, rouge, wer]
library_name: transformers  # or diffusers, sentence-transformers
base_model: bert-base-uncased
widget:
  - text: "Example input"
    example_title: "Sample Demonstration"
```

**Dataset Repository Metadata**:
```yaml
task_categories: (REQUIRED)
  - Options: {", ".join(_EXPECTED_TASKS)}
  - Format: List of string value (all items used must be one of the above), you must use a list even though there is only 1 item
language: (REQUIRED) # ISO 639-1 codes
  - Format: [en, zh, fr, de, es, multilingual]
license: (REQUIRED) 
  - Default: cc-by-4.0 (if no original license found)

# Recommended fields
size_categories: 
  - Options: n<1K, 1K<n<10K, 10K<n<100K, 100K<n<1M, 1M<n<10M, n>10M
source_datasets: 
  - Format: [original, extended|username/dataset]

# Optional fields
task_ids: [named-entity-recognition, sentiment-analysis]
configs: [en_base, zh_simplified]
version: 1.0.0
```

#### 3. Content Structure Template
````markdown
---
# METADATA BLOCK HERE
---

# [Main Title: Concise and Descriptive]

## Summary
[200+ word description with 3-5 **bolded keywords**]
- First paragraph: Core functionality and key innovation
- Second paragraph: Technical approach and methodology
- Third paragraph: Performance highlights and use cases
- Fourth paragraph: Dataset/model characteristics
- Keywords: **Keyword1**, **Keyword2**, **Keyword3**

## Usage
```bash
# Installation
pip install [required packages]
```
```python
# Example Code
[Complete runnable example with imports, loading, and execution]
```

# Citation
```bibtex
[Complete BibTeX entry - preserve original or generate if available]
```
````

#### 4. Citation Section Rules
1. **Position**: Always place at the **end** of the README
2. **Content Determination**:
   - **Non-Original Work** (derivative models/datasets):
     - Point to original authors and source
     - Include full original citation details
     - Add note: "This repository provides an implementation/adaptation of the original work"
   - **Original Work** (novel contribution):
     - Cite this repository as the primary source
     - Include comprehensive details about the work
3. **Format Requirements**:
   - Wrap in triple-backtick code block with `bibtex` language identifier
   - Follow standard BibTeX format with complete metadata

4. **Citation Templates**:
```bibtex
# For ORIGINAL WORK (this repository is the source)
@misc{{repository_identifier,
  title        = {{Full Repository Title}},
  author       = {{Author1 and Author2 and ...}},
  howpublished = {{\\url{{https://huggingface.co/username/repo}}}},
  year         = {{2023}},
  note         = {{Summary of key contributions: [1-2 sentence abstract]}},
  abstract     = {{Full 200+ word abstract from the Summary section}},
  keywords     = {{Keyword1, Keyword2, Keyword3}}
}}

# For NON-ORIGINAL WORK (pointing to original source)
@inproceedings{{original_paper,
  title     = {{Original Paper Title}},
  author    = {{Original Author1 and Original Author2}},
  booktitle = {{Conference/Journal Name}},
  year      = {{2020}},
  url       = {{https://arxiv.org/abs/xxxx.xxxxx}}
}}
@misc{{original_repository,
  title        = {{Original Repository Title}},
  author       = {{Original Maintainer}},
  howpublished = {{\\url{{https://huggingface.co/original/repo}}}},
  year         = {{2022}},
  note         = {{This repository provides an implementation/adaptation of the original work}}
}}
```

5. **Metadata Requirements**:
   - Must include:
     - `title`: Full repository name/title
     - `author`: All contributors (format: "Name1 and Name2 and ...")
     - `howpublished`: Full Hugging Face repository URL
     - `year`: Creation/publication year
     - `note`: Brief 1-2 sentence summary of key contributions
     - `abstract`: Full abstract from the Summary section
     - `keywords`: 3-5 keywords from the Summary section
   - Optional but recommended:
     - `doi`: Digital Object Identifier if available
     - `version`: Model/dataset version

6. **Originality Determination**:
   - Considered **Original Work** if:
     - Novel architecture/methodology introduced
     - New dataset created (not derived from existing)
     - Significant original contributions beyond fine-tuning
   - Considered **Non-Original** if:
     - Direct fine-tune of existing model
     - Minor adaptation of existing work
     - Derived from existing dataset with minimal changes

7. **Information Sourcing**:
   - Author names: From repository owners/contributors
   - Year: From creation date in repository history
   - Abstract: Use the generated Summary section content
   - Keywords: Use the bolded keywords from Summary
   - Title: Use the main repository title

8. **Fallback for Missing Information**:
```bibtex
@misc{{repository,
  title        = {{Repository Title}},
  author       = {{Repository Contributors}},
  howpublished = {{\\url{{https://huggingface.co/username/repo}}}},
  year         = {{2023}},
  note         = {{[Brief description from metadata or summary]}}
}}
```

This revised approach ensures proper attribution while providing rich, reusable citation metadata that:
1. Gives appropriate credit for original work
2. Provides comprehensive information for academic citation
3. Maintains direct connection to the repository
4. Includes all necessary elements for LaTeX/BibTeX users
5. Clearly distinguishes between original and derivative works

#### 5. Critical Preservation Rules
1. **Exact Copy Requirements**:
   - Tables: Preserve every character, space, and alignment
   - Code blocks: Maintain original formatting and comments
   - Mathematical notation: Keep all LaTeX expressions ($...$ and $$...$$) unchanged
   - Hyperlinks: Preserve all URL formats and anchor texts

2. **Content Organization**:
   - Retain all original section headers
   - Maintain original bullet points and numbering
   - Preserve all image references: `![Alt Text](url)`
   - Keep all citations and references intact

3. **License Handling**:
   - Body text: Only include license information if present in original README
   - Metadata: Always include license field (use defaults if missing)

4. Use dghs-imgutils/dghs-realutils library directly if possible, do not just repeat the code from them.

5. The provided source code in extra content part may contain rst format docs, if you use those content you should make sure all the content is transformed to markdown fomat. e.g. `xxx <yyy>`_ to [xxxx](yyyy), etc.

6. For dataset repositories, unless there is very explicit clues of some library supported (e.g. cheesechaser, dghs-imgutils or huggingface datasets, etc, for dghs-imgutils, you can only use this when you see it in original README or I give you some information about this in the user prompt, otherwise you are forbidden to use it), you do not have to provide example code of using it.
   DO NOT TRY TO GUESS its usage like dghs-imgutils unless I explicitly told you.
   DO NOT TRY TO GUESS its datasets library usages unless you see something like 'datasets_info.json'.

7. You should keep the original key contents in the old version of README.md (if exist).
   Especially for the original tables, you should 100% keep it in your output without any changes, and organize those content in a good way. 

#### 6. Special Case Handling
- **No original README**:
  - Generate comprehensive summary from file structure and data samples
  - Create usage section from downstream library documentation
  - Include "Original Content" section with repository file tree

- **Multiple languages**:
  - Add language-specific tags (zh, ja, ko)
  - Include multilingual examples in usage section
  - Preserve all original language content without translation

- **Conflicting information**:
  - Prioritize original README content over user descriptions
  - Preserve original technical specifications verbatim
  - Add metadata comments for potential inconsistencies

#### 7. Validation Checks
Before output, verify:
- Metadata block is valid YAML with required fields
- Summary contains â‰¥200 words and 3-5 bolded keywords
- All original tables/code blocks are preserved exactly
- License field exists in metadata (even if missing in body)
- Citation section is properly formatted BibTeX
- No external commentary or markdown wrappers added

**Output Format**: Raw README.md content only - no prefixes, suffixes, or explanations. Ready for direct use on Hugging Face Hub.
    """).strip()

    cnt = 0
    text = None
    while cnt < max_retries:
        try:
            text = ask_llm(
                prompts=[
                    {
                        "role": "system",
                        "content": _SYSTEM_PROMPT,
                    },
                    {
                        "role": "user",
                        "content": get_hf_repo_abstract_prompt(
                            repo_id=repo_id,
                            repo_type=repo_type,
                            revision=revision,
                            hf_token=hf_token,
                            max_retries=max_retries,
                            max_sample_count=max_sample_count,
                        ) + f'\n\n## Extra Content\n\n{textwrap.dedent(extra_text).strip()}',
                    }
                ],
                # model_name='deepseek-reasoner',
                model_name='deepseek-chat',
            )

        except:
            cnt += 1
            if cnt > max_retries:
                raise
            logging.exception(f'Error on parsing ({cnt}/{max_retries}) ...')
        else:
            break

    if text:
        with TemporaryDirectory() as upload_dir:
            with open(os.path.join(upload_dir, 'README.md'), 'w') as f:
                print(text, file=f)

            upload_directory_as_directory(
                repo_id=repo_id,
                repo_type=repo_type,
                local_directory=upload_dir,
                path_in_repo='.',
                message=f'Auto-update README.md via abstractor',
            )


if __name__ == '__main__':
    logging.try_init_root(level=logging.INFO)
    sync(
        repo_id='deepghs/csip_eval',
        repo_type='dataset',
        extra_text=('''
CSIP = (Contrastive anime Style Image Pre-Training), this is the dataset of CSIP
containing different images of different anime artists
this is the human-picked version, suitable for evaluation

If you are looking for the uncleaned one: [deepghs/csip](https://huggingface.co/datasets/deepghs/csip)
If you are looking for the roughly cleaned one: [deepghs/csip_v1](https://huggingface.co/datasets/deepghs/csip_v1)
If you are looking for the human picked one: [deepghs/csip_eval](https://huggingface.co/datasets/deepghs/csip_eval) (but maybe small, just okay for evaluation) 
        ''')
    )
